Module 9 Assessment

Group 3: (Sharif Rakhimov, Will Stearns, Derek Preslar, Phil Carbino)

README:

Hello, and welcome to our repository for the Module 09 group assessment.

In this exercise, we were placed into groups of four to research machine learning algorithms and present our findings to the rest of the class. The exercise consisted of two parts, both of which are outlined below.



Part I

In this portion of the assessment, our group researched a machine learning algortihm that was previously not covered in class. Our group studied the 'Naive Bayes' algorithm.

After our research, we were asked to create an 8-12 minute presentation on our designated algorithm, giving a semi technical, high level overview of:

What it does and how it works,

What the advantages and disadvantages of using it are,

What specific data processing steps should be followed before implementing the model, and

What the relevant hyperparameters are and how can they be tuned.

Following these guidelines, we created a Powerpoint presentation which can be found in the 'Naive Bayes Notes' file. These is also a PDF version under the name 'naive-bayes-presentation'.

We also put together an appendix with links to sources of our research that we used and felt would help explain the algorithm to anyone who might want to learn more about it. It consists of video tutorials, academic papers, as well as detailed blog posts about its functions, uses and examples of how it can be implemeted. The appendix is available as a PDF in the 'naive_bayes_appendix' file.



Part II

In this portion of the assessment, our group set out to implement a model using an algotithm researched by one of the other groups. In this case, we were tasked with implementing the 'SVM', or 'Support Vector Machine' algorithm.

To complete this task, we first studied the presentation materials and appendix via the github repository provided by the group who initially researched the algortihm:
(https://github.com/OnionYams/M9-Assess-Group2)

After researching the algorithm a bit on our own, we then had to choose a dataset that was previously used in another class exercise with which to implement the algortithm. The Pima Indians Diabetes Database seemed particularly well suited for our needs, so we decided to base our model on it. In our repository, the dataset is in the 'diabetes.csv' file, which can also be downloaded here:
(https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)

Our next task was to write code to actually implement the algorithm, assess its performance, and compare it to another algorithm we've dealt with in the past. Here we've compared the SVM algorithm to Logistic Regression.

We've created a short presentation on our findings using SVM, and the Powerpoint slides can be found in the 'group-3-M09-final-presentation.pptx' file. A PDF version is also available.
